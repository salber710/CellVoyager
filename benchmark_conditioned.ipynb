{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/samuelalber/Documents/Research/jzou/salber/scAgent_v2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import openai\n",
    "print(os.getcwd())\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = openai.OpenAI()\n",
    "\n",
    "home_dir = \"/Users/samuelalber/Documents/Research/jzou/salber/scAgent_v2\"\n",
    "csv_path_1 = os.path.join(home_dir, \"gemini_2.5_pro_qa_conditioned.csv\")\n",
    "csv_path_2 = os.path.join(home_dir, \"gemini_2.5_pro_qa_conditioned_p2.csv\")\n",
    "\n",
    "df_1 = pd.read_csv(csv_path_1)\n",
    "df_2 = pd.read_csv(csv_path_2)\n",
    "df = pd.concat([df_1, df_2])\n",
    "df['analyses_include'] = df['analyses_include'].apply(eval)\n",
    "df['analyses_rest'] = df['analyses_rest'].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyses_overview = open(os.path.join(home_dir, \"prompts\", \"DeepResearch_Analyses.txt\")).read()\n",
    "\n",
    "\n",
    "first_draft_prompt = f\"\"\"\n",
    "You will be provided the background/introduction from a research paper as well as a set of computational analyses from the research paper.\n",
    "The rest of the computational analyses done in the paper are hidden from you.\n",
    "\n",
    "Your role is to propose a computational analysis that you think was done in the hidden part of the paper.\n",
    "\n",
    "Ensure that your output is in the specified JSON format.\n",
    "\n",
    "For the analysis plan, think of the analysis plan as a scientific workflow:\n",
    "    1. Start with exploratory data analysis that is broad and tests many things\n",
    "    2. Then, focus on the more promising results from the exploratory phase by creating more focused analyses\n",
    "    3. Include statistical validation of your results where appropiate\n",
    "Do not number the analysis plan.\n",
    "Each step in the analysis plan should be distinct from one another and could involve loading the data, conducting a statistical analysis, printing information about the AnnData object, etc.\n",
    "Use however many steps is appropiate, but go for at least 5 steps. \n",
    "\n",
    "\n",
    "Ensure that your analyses solely use data explicitly mentioned in the paper. For example, if only RNA-seq data is mentioned, do NOT suggest spatial.\n",
    "Likewise, if no spliced/unspliced RNA counts are mentioned, do NOT suggest RNA velocity.\n",
    "\n",
    "Here are the previous analyses attempted:\n",
    "{{past_analyses}}\n",
    "\n",
    "Here is the background information from the paper and the subset of computational analyses:\n",
    "{{paper_txt}}\n",
    "\n",
    "For the rest of the prompt, we have examples of potential analyses:\n",
    "{analyses_overview}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "system_prompt = f\"\"\"\n",
    "You are a creative and skilled expert in single-cell transcriptomics computational analysis.\n",
    "\n",
    "Output your response in the following JSON format (do not number the analysis steps, just list them):\n",
    "{{\n",
    "    \"hypothesis\": \"...\",\n",
    "    \"analysis_plan\": [\"First step\", \"Second step\", ...],\n",
    "    \"summary\": \"A string describing the analysis in a detailed paragraph outlining how you will conduct the analysis\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "critic_prompt = f\"\"\"\n",
    "You will be given a hypothesis, analysis plan, and a summary of the analysis plan.\n",
    "This analysis was generated by being given the background/introduction from a research paper (shown below) and a subset of the computational analyses in the research paper.\n",
    "The rest of the computational analyses are hidden and the goal is to propose a computational analysis that is likely to be in that hidden set.\n",
    "\n",
    "Your role is to provide feedback for the analysis based on these goals.\n",
    "\n",
    "Ensure that the analyses solely uses data explicitly mentioned in the paper. For example, if only RNA-seq data is mentioned, the analysis should NOT involve spatial analyses.\n",
    "Likewise, if no spliced/unspliced RNA counts are mentioend, the analysis should NOT suggest RNA velocity.\n",
    "\n",
    "Analysis Summary:\n",
    "{{summary}}\n",
    "\n",
    "Analysis Hypothesis:\n",
    "{{hypothesis}}\n",
    "\n",
    "Analysis Plan:\n",
    "{{analysis_plan}}\n",
    "\n",
    "Here is the background information from the paper and the subset of computational analyses:\n",
    "{{paper_txt}}\n",
    "\n",
    "Previous Analysis Attempted:\n",
    "{{past_analyses}}\n",
    "\n",
    "For the rest of the prompt, we have examples of potential analyses:\n",
    "{analyses_overview}\n",
    "\"\"\"\n",
    "\n",
    "incorporate_prompt = f\"\"\"\n",
    "You will be given a hypothesis, analysis plan, and a summary of the analysis plan.\n",
    "This analysis was generated by being given the background/introduction from a research paper (shown below) and a subset of the computational analyses in the research paper.\n",
    "The rest of the computational analyses are hidden and the goal is to propose a computational analysis that is likely to be in that hidden set.\n",
    "\n",
    "You will also be given feedback for the analysis in order so that it achieves these goals. \n",
    "Your role is to incorporate that feedback and update the analysis components (summary, hypothesis, analysis plan)\n",
    "\n",
    "Analysis Summary:\n",
    "{{summary}}\n",
    "\n",
    "Analysis Hypothesis:\n",
    "{{hypothesis}}\n",
    "\n",
    "Analysis Plan:\n",
    "{{analysis_plan}}\n",
    "\n",
    "Feedback:\n",
    "{{feedback}}\n",
    "\n",
    "Here are the previous analyses attempted:\n",
    "{{past_analyses}}\n",
    "\n",
    "Here is the background information from the paper and the subset of computational analyses:\n",
    "{{paper_txt}}\n",
    "\n",
    "For the rest of the prompt, we have examples of potential analyses:\n",
    "{analyses_overview}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(prompt, system_prompt, use_json=False):\n",
    "    if use_json:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        result = response.choices[0].message.content\n",
    "        return json.loads(result)\n",
    "    else:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "        )\n",
    "        result = response.choices[0].message.content\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 14 analyses for paper 1\n",
      "Running 1/14\n"
     ]
    }
   ],
   "source": [
    "#if not os.path.exists(agent_output_path):\n",
    "NUM_RUN = 5\n",
    "for i in range(NUM_RUN):\n",
    "    index = i + 1\n",
    "    agent_output_path = os.path.join(home_dir, f\"agent_analyses_conditioned_gpt4o_{index}.json\")\n",
    "    all_agent_analyses = []\n",
    "    for i, row in df.iterrows():\n",
    "        context = row['context']\n",
    "        analyses_rest_paper = row['analyses_rest']\n",
    "        analyses_include_paper = row['analyses_include']\n",
    "\n",
    "        for index, analysis in enumerate(analyses_include_paper):\n",
    "            analysis_description = analysis['description']\n",
    "            context += f\"\\nPaper Analysis {index + 1}:\\n{analysis_description}\"\n",
    "        # Save context to temporary file\n",
    "        temp_file = \"temp_uncond.txt\"\n",
    "        with open(temp_file, \"w\") as f:\n",
    "            f.write(context)\n",
    "\n",
    "        past_analyses = \"\"\n",
    "        for analysis in analyses_include_paper:\n",
    "            past_analyses += f\"{analysis}\\n\\n\"\n",
    "\n",
    "        agent_analyses = []\n",
    "        print(f\"Running {len(analyses_rest_paper)} analyses for paper {i+1}\")\n",
    "        for j in range(len(analyses_rest_paper)):\n",
    "            print(f\"Running {j+1}/{len(analyses_rest_paper)}\")\n",
    "            first_draft_prompt_filled = first_draft_prompt.format(past_analyses=past_analyses, paper_txt=context)\n",
    "            first_draft = get_response(first_draft_prompt_filled, system_prompt, use_json=True)\n",
    "\n",
    "            hypothesis, analysis_plan, summary = first_draft[\"hypothesis\"], first_draft[\"analysis_plan\"], first_draft[\"summary\"]\n",
    "            critic_prompt_filled = critic_prompt.format(summary=summary, hypothesis=hypothesis, analysis_plan=analysis_plan, \n",
    "                                                    paper_txt=context, past_analyses=past_analyses)\n",
    "            feedback = get_response(critic_prompt_filled, \"You are a single-cell bioinformatics expert providing feedback on code and analysis plan.\", use_json=False)\n",
    "\n",
    "            incorporate_prompt_filled = incorporate_prompt.format(summary=summary, hypothesis=hypothesis, analysis_plan=analysis_plan, \n",
    "                                                                    feedback=feedback, past_analyses=past_analyses, paper_txt=context)\n",
    "            final_analysis = get_response(incorporate_prompt_filled, system_prompt, use_json=True)\n",
    "\n",
    "            analysis = final_analysis['summary']\n",
    "            agent_analyses.append(analysis)\n",
    "            past_analyses += f\"{analysis}\\n\\n\"\n",
    "\n",
    "        all_agent_analyses.append(agent_analyses)\n",
    "\n",
    "        # Save intermediate result after each iteration\n",
    "        with open(agent_output_path, \"w\") as f:\n",
    "            json.dump(all_agent_analyses, f, indent=2)\n",
    "\n",
    "        # Delete temporary file\n",
    "        os.remove(temp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "analyses_rest = df['analyses_rest'].tolist()\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = openai.OpenAI(api_key=api_key)\n",
    "with open(agent_output_path, \"r\") as f:\n",
    "    all_agent_analyses = json.load(f)\n",
    "all_judge_responses = []\n",
    "for i, agent_analysis_list in enumerate(all_agent_analyses):\n",
    "    print(i)\n",
    "    judge_responses = []\n",
    "    for j, agent_analysis in enumerate(agent_analysis_list):\n",
    "        prompt = f\"\"\"\n",
    "        You are given a proposed analysis for single-cell transcriptomics and a set of ground truth analyses. Your task is to determine whether the proposed analysis matches at least one analysis from the set of ground truth analyses.\n",
    "\n",
    "        Proposed:\n",
    "        {agent_analysis}\n",
    "\n",
    "        Ground truth:\n",
    "        {analyses_rest[i]}\n",
    "\n",
    "        Give your answer in the following format:\n",
    "        {{\n",
    "            \"match\": true/false,\n",
    "            \"reason\": \"explanation of the match or mismatch and if match, which analysis it matches\"\n",
    "        }}\n",
    "        \"\"\"\n",
    "        response = client.responses.create(\n",
    "            model=\"gpt-4o\",\n",
    "            input=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"input_text\",\n",
    "                            \"text\": prompt,\n",
    "                        },\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        response = response.output_text\n",
    "        judge_responses.append(response)\n",
    "    all_judge_responses.append(judge_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.47218253968253965, 0.4868421052631579)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_response(response):\n",
    "    if isinstance(response, str):\n",
    "        response = response.replace('```json', '').replace('```python', '').replace('```', '').strip()\n",
    "        parsed = json.loads(response)\n",
    "    elif isinstance(response, list):\n",
    "        parsed = []\n",
    "        for r in response:\n",
    "            r = r.replace('```json', '').replace('```python', '').replace('```', '').strip()\n",
    "            r = json.loads(r)\n",
    "            parsed.append(r)\n",
    "    return parsed\n",
    "\n",
    "df = pd.DataFrame({'raw_judge_response': all_judge_responses})\n",
    "df['parsed_judge_response'] = df['raw_judge_response'].apply(parse_response)\n",
    "df['num_match'] = df['parsed_judge_response'].apply(lambda x: sum(map(lambda y: int(y['match']), x)))\n",
    "num_per_paper = df['parsed_judge_response'].apply(len)\n",
    "micro_avg = (df['num_match'] / num_per_paper).mean()\n",
    "macro_avg = df['num_match'].sum() / num_per_paper.sum()\n",
    "micro_avg, macro_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.44092352092352094, 0.4507042253521127)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_response(response):\n",
    "    if isinstance(response, str):\n",
    "        response = response.replace('```json', '').replace('```python', '').replace('```', '').strip()\n",
    "        parsed = json.loads(response)\n",
    "    elif isinstance(response, list):\n",
    "        parsed = []\n",
    "        for r in response:\n",
    "            r = r.replace('```json', '').replace('```python', '').replace('```', '').strip()\n",
    "            r = json.loads(r)\n",
    "            parsed.append(r)\n",
    "    return parsed\n",
    "\n",
    "df = pd.DataFrame({'raw_judge_response': all_judge_responses})\n",
    "df['parsed_judge_response'] = df['raw_judge_response'].apply(parse_response)\n",
    "df['num_match'] = df['parsed_judge_response'].apply(lambda x: sum(map(lambda y: int(y['match']), x)))\n",
    "num_per_paper = df['parsed_judge_response'].apply(len)\n",
    "micro_avg = (df['num_match'] / num_per_paper).mean()\n",
    "macro_avg = df['num_match'].sum() / num_per_paper.sum()\n",
    "micro_avg, macro_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.29, 0.29577464788732394)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_response(response):\n",
    "    if isinstance(response, str):\n",
    "        response = response.replace('```json', '').replace('```python', '').replace('```', '').strip()\n",
    "        parsed = json.loads(response)\n",
    "    elif isinstance(response, list):\n",
    "        parsed = []\n",
    "        for r in response:\n",
    "            r = r.replace('```json', '').replace('```python', '').replace('```', '').strip()\n",
    "            r = json.loads(r)\n",
    "            parsed.append(r)\n",
    "    return parsed\n",
    "\n",
    "df = pd.DataFrame({'raw_judge_response': all_judge_responses})\n",
    "df['parsed_judge_response'] = df['raw_judge_response'].apply(parse_response)\n",
    "df['num_match'] = df['parsed_judge_response'].apply(lambda x: sum(map(lambda y: int(y['match']), x)))\n",
    "num_per_paper = df['parsed_judge_response'].apply(len)\n",
    "micro_avg = (df['num_match'] / num_per_paper).mean()\n",
    "macro_avg = df['num_match'].sum() / num_per_paper.sum()\n",
    "micro_avg, macro_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'match': False,\n",
       "  'reason': 'The proposed analysis emphasizes pathway enrichment to characterize cellular heterogeneity, dynamic processes, and trajectory inference using curated gene sets and SCVI for batch correction. It also discusses integrating visualization techniques and aims to understand the functional diversity within the OSCC-GB tumor microenvironment. None of the ground truth analyses specifically match this approach in terms of using pathway enrichment as the main focus or utilizing SCVI for batch correction and clustering. Although some ground truth analyses involve pathway enrichment, they do not focus on the proposed broad integration of pathway scoring, trajectory inference, and SCVI. Therefore, there is no direct match.'},\n",
       " {'match': False,\n",
       "  'reason': 'The proposed analysis focuses on delineating cell-cell communication networks using frameworks like CellPhoneDB or NicheNet, emphasizing interactions involving non-epithelial cells and multi-omics integration. None of the ground truth analyses focus on these aspects. They primarily involve subclustering, characterization, pseudo-time trajectory analysis of specific cell types like malignant, T, B, myeloid, and other immune cells, or driver gene co-expression and comparison with bulk RNA-seq data. No analysis among the ground truths matches the emphasis on non-epithelial cell communication networks or the integration of multi-omics data as described in the proposed analysis.'},\n",
       " {'match': False,\n",
       "  'reason': 'The proposed analysis focuses on identifying distinct metabolic states and vulnerabilities in OSCC-GB tumors using single-cell transcriptomics, pathway scoring, trajectory inference with PAGA, regulatory network analysis via SCENIC, ligand-receptor interaction evaluations, and machine learning models. None of the ground truth analyses specifically match this combination and focus, as they primarily deal with clustering, differential gene expression, pseudotime trajectory analysis, and subclustering of different cell types without a specific emphasis on metabolic state analysis and machine learning integrations.'},\n",
       " {'match': True,\n",
       "  'reason': \"The proposed analysis matches the ground truth analysis titled 'Subclustering and Characterization of T Cells'. Both analyses focus on the exploration of immune subpopulations, employing clustering techniques to identify subtypes of immune cells. The proposed analysis also employs similar methods such as pseudotime analysis (mentioned with Monocle or Velocyto), immune cell characterization, and visualization techniques like t-SNE or UMAP, which are consistent with approaches typically used in immune cell and microenvironment exploration.\"},\n",
       " {'match': False,\n",
       "  'reason': 'The proposed analysis focuses on investigating transcription factor activity, metabolic states, cell-cell communication, and trajectory analysis in OSCC-GB tumors, using methods like SCENIC, pseudotime mapping, and CellPhoneDB. The ground truth analyses cover subclustering, gene expression, pseudotime analysis, and pathway enrichment in various cell types, but none specifically match the comprehensive focus on transcription factor activity and integration of metabolic and communication networks as described in the proposed analysis.'},\n",
       " {'match': False,\n",
       "  'reason': 'The proposed analysis focuses on an integrative approach using single-cell RNA-seq and scATAC-seq data with specific techniques for quality control, data integration, machine learning for chromatin accessibility prediction, clustering, and differential expression in OSCC-GB tumors. The ground truth analyses do not describe the use of scATAC-seq data, machine learning models like Cicero or chromVAR, or specific epigenetic analysis approaches as outlined in the proposed method. While both involve single-cell transcriptomics, the methodologies and focus areas are substantially different.'},\n",
       " {'match': True,\n",
       "  'reason': \"The proposed analysis matches one of the ground truth analyses titled 'Pseudotime Trajectory Analysis of Malignant Cells'. The proposed analysis mentions the application of pseudotime analysis to map dynamic transitions in OSCC-GB tumorigenesis, which aligns with the use of pseudotime analysis in the ground truth to infer developmental trajectories and relationships in malignant cells.\"},\n",
       " {'match': True,\n",
       "  'reason': \"The proposed analysis matches with the ground truth analysis titled 'Pseudotime Trajectory Analysis of Malignant Cells'. Both involve pseudotime analysis to infer developmental trajectories and relationships between different malignant cell states. However, the proposed analysis incorporates additional techniques such as CellRank for pseudotime inference and suggests integration of scATAC-seq data.\"},\n",
       " {'match': False,\n",
       "  'reason': 'The proposed analysis focuses on exploring the role of epigenetic regulators in cellular states by integrating single-cell transcriptomic and epigenomic data, particularly emphasizing chromatin accessibility and using techniques like ChromVAR/R and Cicero. None of the ground truth analyses incorporate both transcriptomic and epigenomic data with a focus on epigenetic regulation or chromatin accessibility. The ground truth analyses instead focus on clustering and characterizing various cell types, pseudotime trajectory analysis, and differential expression within particular cell types, without the integration of chromatin accessibility analysis or epigenomic data. Therefore, the proposed analysis does not match any of the ground truth analyses.'},\n",
       " {'match': False,\n",
       "  'reason': \"The proposed analysis focuses on spatial transcriptomic techniques, spatial clustering, spatial differential expression analyses, integration of spatial ligand-receptor interactions, and the exploration of the epigenetic landscape's contribution to spatial patterns. None of the ground truth analyses specifically involve spatial transcriptomics or the integration of scATAC-seq data to explore spatial heterogeneity and patterning in OSCC-GB tumors. Additionally, the use of specific techniques mentioned such as SpaGCN, BayesSpace, SpatialPCA, and SpaOTsc in spatial contexts is not described in any ground truth analysis. Therefore, the proposed analysis does not match any of the ground truth analyses.\"},\n",
       " {'match': False,\n",
       "  'reason': 'The proposed analysis focuses on the transcriptional and regulatory landscape of OSCC-GB tumors using a WGCNA framework to identify gene co-expression modules, integrating chromatin accessibility data, and performing pathway enrichment with tools like clusterProfiler. There is an emphasis on co-expression network analysis, regulatory dynamics, and visualization with Cytoscape and Gephi. None of the ground truth analyses match this approach. The ground truth analyses involve various methods such as subclustering, characterization, pseudotime trajectory analysis, and comparison of data types, but do not incorporate WGCNA or integrate chromatin accessibility data in the same comprehensive manner as described in the proposed analysis.'},\n",
       " {'match': False,\n",
       "  'reason': 'The proposed analysis focuses on investigating transcriptional regulatory mechanisms and tumor progression in OSCC-GB using SCENIC for gene regulatory network inference, pathway enrichment, statistical validation, and additional insights into cell-cell communication and metabolic states. On the other hand, the ground truth analyses primarily entail subclustering and characterization of specific cell populations (e.g., malignant cells, T cells, B cells, endothelial cells, etc.), pseudotime trajectory analyses, immune-related gene expression, driver gene co-expression patterns, and comparisons with bulk RNA-seq data. None of the ground truth analyses align with the specific objectives and methodologies described in the proposed analysis.'},\n",
       " {'match': False,\n",
       "  'reason': 'The proposed analysis focuses on exploring spatial architecture and simulating spatial transcriptomic patterns within OSCC-GB tumors using single-cell RNA-seq data, incorporating spatial tools like SpaGCN, BayesSpace, and SpaOTsc. It aims to perform spatial differential expression analyses and integrate ligand-receptor interactions to understand tumor biology in a spatial context. None of the ground truth analyses specifically address spatial transcriptomics or utilize the proposed tools like SpaGCN or BayesSpace. The ground truth analyses mainly focus on clustering, differential expression, pseudotime analysis, immune-related gene expression, and specific cell type subcluster characterization rather than spatial transcriptomic simulation or analysis.'},\n",
       " {'match': False,\n",
       "  'reason': 'The proposed analysis focuses on the role of stress response pathways in OSCC-GB tumors, integrating environmental influences, and using techniques like pathway scoring, visualization, machine learning, trajectory analysis, and scATAC-seq validation. None of the ground truth analyses explicitly match this proposal. The ground truth analyses involve studying malignant cell heterogeneity, gene expression related to immune and EMT pathways, subclustering various cell types (e.g., T cells, B cells, fibroblasts), pseudotime analysis, and comparison with bulk RNA-seq data. None specifically address stress response pathways or the comprehensive integration of environmental factors as described in the proposed analysis.'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['parsed_judge_response'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, agent_analysis_list in enumerate(all_agent_analyses):\n",
    "    judge_responses = []\n",
    "    for j, agent_analysis in enumerate(agent_analysis_list):\n",
    "        print(agent_analysis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "single-cell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
